// Copyright 2019 Ryan Curtin (http://www.ratml.org/)
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// ------------------------------------------------------------------------

// utility functions for compiled-on-the-fly CUDA kernels

inline
std::string
get_cuda_src_preamble()
  {
  std::string source = \

  "#define uint unsigned int\n"
  "#define COOT_FN2(ARG1, ARG2)  ARG1 ## ARG2 \n"
  "#define COOT_FN(ARG1,ARG2) COOT_FN2(ARG1,ARG2)\n"
  "\n"
  "extern \"C\" {\n"
  "\n"
  "extern __shared__ char aux_shared_mem[]; \n" // this may be used in some kernels
  "\n";

  return source;
  }



inline
std::string
get_cuda_src_epilogue()
  {
  return "}\n";
  }

// shitty single kernel for fill()

inline
std::string
get_cuda_oneway_kernel_src()
  {
  // NOTE: kernel names must match the list in the kernel_id struct

  std::string source = \

  "__global__ void COOT_FN(PREFIX,inplace_set_scalar)(eT1* out, const eT1 val, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)  { out[i] = val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_plus_scalar)(eT1* out, const eT1 val, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)  { out[i] += val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_minus_scalar)(eT1* out, const eT1 val, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)  { out[i] -= val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_mul_scalar)(eT1* out, const eT1 val, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)  { out[i] *= val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_div_scalar)(eT1* out, const eT1 val, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)  { out[i] /= val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_set_scalar)(eT1* out, const eT1 val, const UWORD end_row, const UWORD end_col, const UWORD n_rows, const UWORD start_row, const UWORD start_col) \n"
  "  { \n"
  "  const UWORD row = start_row + blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = start_col + blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if ((row <= end_row) && (col <= end_col)) \n"
  "    { out[row + col * n_rows] = val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_plus_scalar)(eT1* out, const eT1 val, const UWORD end_row, const UWORD end_col, const UWORD n_rows, const UWORD start_row, const UWORD start_col) \n"
  "  { \n"
  "  const UWORD row = start_row + blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = start_col + blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if ((row <= end_row) && (col <= end_col)) \n"
  "    { out[row + col * n_rows] += val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_minus_scalar)(eT1* out, const eT1 val, const UWORD end_row, const UWORD end_col, const UWORD n_rows, const UWORD start_row, const UWORD start_col) \n"
  "  { \n"
  "  const UWORD row = start_row + blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = start_col + blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if ((row <= end_row) && (col <= end_col)) \n"
  "    { out[row + col * n_rows] -= val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_mul_scalar)(eT1* out, const eT1 val, const UWORD end_row, const UWORD end_col, const UWORD n_rows, const UWORD start_row, const UWORD start_col) \n"
  "  { \n"
  "  const UWORD row = start_row + blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = start_col + blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if ((row <= end_row) && (col <= end_col)) \n"
  "    { out[row + col * n_rows] *= val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_div_scalar)(eT1* out, const eT1 val, const UWORD end_row, const UWORD end_col, const UWORD n_rows, const UWORD start_row, const UWORD start_col) \n"
  "  { \n"
  "  const UWORD row = start_row + blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = start_col + blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if ((row <= end_row) && (col <= end_col)) \n"
  "    { out[row + col * n_rows] /= val; } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_set_eye)(eT1* out, const UWORD n_rows, const UWORD n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if( (row < n_rows) && (col < n_cols) ) \n"
  "    { \n"
  "    const UWORD offset = row + col * n_rows; \n"
  "    out[offset] = (row == col) ? (eT1)(1) : (eT1)(0); \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,accu_simple)(eT1* out, const eT1* A, const UWORD A_len) \n"
  "  { \n"
  "  const UWORD id = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(id == 0) \n"
  "    { \n"
  "    eT1 acc = (eT1)(0); \n" // runtime unrolling is not supported by CUDA
  "    for(UWORD i=0; i<A_len; ++i) \n"
  "      { acc += A[i]; } \n"
  "    out[0] = acc; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__device__ void COOT_FN(PREFIX,accu_warp_reduce)(volatile eT1* data, int tid) \n"
  "  { \n"
  "  data[tid] += data[tid + 32]; \n"
  "  data[tid] += data[tid + 16]; \n"
  "  data[tid] += data[tid + 8]; \n"
  "  data[tid] += data[tid + 4]; \n"
  "  data[tid] += data[tid + 2]; \n"
  "  data[tid] += data[tid + 1]; \n"
  "  } \n"
  "\n"
  // this kernel is technically incorrect if the size is not a factor of 2!
  "__global__ void COOT_FN(PREFIX,accu)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  aux_mem[tid] = 0; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += in_mem[i] + in_mem[i + blockDim.x]; \n" // copy to local shared memory
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += in_mem[i]; \n"
  "    } \n"
  "  __syncthreads(); \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 32; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] += aux_mem[tid + s]; \n"
  "      } \n"
  "    __syncthreads(); \n"
  "  } \n"
  "  \n"
  "  if (tid < 32) \n" // unroll last warp's worth of work
  "    { \n"
  "    COOT_FN(PREFIX,accu_warp_reduce)(aux_mem, tid); \n"
  "    } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,accu_small)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  aux_mem[tid] = 0; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += in_mem[i] + in_mem[i + blockDim.x]; \n" // copy to local shared memory
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += in_mem[i]; \n"
  "    } \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 0; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] += aux_mem[tid + s]; \n"
  "      } \n"
  "  } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__device__ void COOT_FN(PREFIX,min_warp_reduce)(volatile eT1* data, int tid) \n"
  "  { \n"
  "  data[tid] = min(data[tid], data[tid + 32]); \n"
  "  data[tid] = min(data[tid], data[tid + 16]); \n"
  "  data[tid] = min(data[tid], data[tid + 8]); \n"
  "  data[tid] = min(data[tid], data[tid + 4]); \n"
  "  data[tid] = min(data[tid], data[tid + 2]); \n"
  "  data[tid] = min(data[tid], data[tid + 1]); \n"
  "  } \n"
  "\n"
  // this kernel is technically incorrect if the size is not a factor of 2!
  "__global__ void COOT_FN(PREFIX,min)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = in_mem[i]; \n"
  "    } \n"
  "  if (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  i += grid_size; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i]); \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i + blockDim.x]); \n"
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  __syncthreads(); \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 32; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] = min(aux_mem[tid], aux_mem[tid + s]); \n"
  "      } \n"
  "    __syncthreads(); \n"
  "  } \n"
  "  \n"
  "  if (tid < 32) \n" // unroll last warp's worth of work
  "    { \n"
  "    COOT_FN(PREFIX,min_warp_reduce)(aux_mem, tid); \n"
  "    } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,min_small)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = in_mem[i]; \n"
  "    } \n"
  "  if (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  i += grid_size; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i]); \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i + blockDim.x]); \n"
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = min(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 0; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] = min(aux_mem[tid], aux_mem[tid + s]); \n"
  "      } \n"
  "  } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__device__ void COOT_FN(PREFIX,max_warp_reduce)(volatile eT1* data, int tid) \n"
  "  { \n"
  "  data[tid] = max(data[tid], data[tid + 32]); \n"
  "  data[tid] = max(data[tid], data[tid + 16]); \n"
  "  data[tid] = max(data[tid], data[tid + 8]); \n"
  "  data[tid] = max(data[tid], data[tid + 4]); \n"
  "  data[tid] = max(data[tid], data[tid + 2]); \n"
  "  data[tid] = max(data[tid], data[tid + 1]); \n"
  "  } \n"
  "\n"
  // this kernel is technically incorrect if the size is not a factor of 2!
  "__global__ void COOT_FN(PREFIX,max)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = in_mem[i]; \n"
  "    } \n"
  "  if (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  i += grid_size; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i]); \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i + blockDim.x]); \n"
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  __syncthreads(); \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 32; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] = max(aux_mem[tid], aux_mem[tid + s]); \n"
  "      } \n"
  "    __syncthreads(); \n"
  "  } \n"
  "  \n"
  "  if (tid < 32) \n" // unroll last warp's worth of work
  "    { \n"
  "    COOT_FN(PREFIX,max_warp_reduce)(aux_mem, tid); \n"
  "    } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,max_small)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = in_mem[i]; \n"
  "    } \n"
  "  if (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  i += grid_size; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i]); \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i + blockDim.x]); \n"
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], in_mem[i]); \n"
  "    } \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 0; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] = max(aux_mem[tid], aux_mem[tid + s]); \n"
  "      } \n"
  "  } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  // this kernel is technically incorrect if the size is not a factor of 2!
  "__global__ void COOT_FN(PREFIX,max_abs)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = ET1_ABS(in_mem[i]); \n"
  "    } \n"
  "  if (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i])); \n"
  "    } \n"
  "  i += grid_size; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i])); \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i + blockDim.x])); \n"
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i])); \n"
  "    } \n"
  "  __syncthreads(); \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 32; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] = max(aux_mem[tid], aux_mem[tid + s]); \n"
  "      } \n"
  "    __syncthreads(); \n"
  "  } \n"
  "  \n"
  "  if (tid < 32) \n" // unroll last warp's worth of work
  "    { \n"
  "    COOT_FN(PREFIX,max_warp_reduce)(aux_mem, tid); \n"
  "    } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,max_abs_small)(const eT1* in_mem, const UWORD n_elem, eT1* out_mem) \n"
  "  { \n"
  "  eT1* aux_mem = (eT1*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = ET1_ABS(in_mem[i]); \n"
  "    } \n"
  "  if (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i])); \n"
  "    } \n"
  "  i += grid_size; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i])); \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i + blockDim.x])); \n"
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] = max(aux_mem[tid], ET1_ABS(in_mem[i])); \n"
  "    } \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 0; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] = max(aux_mem[tid], aux_mem[tid + s]); \n"
  "      } \n"
  "  } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,trace)(eT1* out, const eT1* A, const UWORD n_rows, const UWORD N) \n"
  "  { \n"
  "  const UWORD id = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(id == 0) \n"
  "    { \n"
  "    eT1 acc = (eT1)(0); \n"
  "    for(UWORD i=0; i<N; ++i) \n" // runtime unrolling is not supported by CUDA
  "      { \n"
  "      acc += A[i + i*n_rows];  \n"
  "      } \n"
  "    out[0] = acc; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,ltri_set_zero)(eT1* out, const UWORD n_rows, const UWORD n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  const UWORD index = col * n_rows + row; \n"
  "  if ( (row < n_rows) && (col < n_cols) && (row > col) ) \n"
  "    { \n"
  "    out[index] = (eT1)(0); \n"
  "    } \n"
  "  } \n"
  "\n";

  return source;
  }




inline
std::string
get_cuda_twoway_kernel_src()
  {
  // NOTE: kernel names must match the list in the kernel_id struct

  std::string source = \

  // TODO: adapt so that auxiliary terms have type eT1 not eT2
  // current dogma will be: eT2(x + val) *not* eT2(x) + eT2(val)
  // however, we should also add the overload eT2(x) + val for those situations
  // the operation, I guess, would look like Op<out_eT, eOp<...>, op_conv_to>
  // and we could add an auxiliary out_eT to Op that's 0 by default, but I guess we need bools to indicate usage?
  // they would need to be added to eOp too
  // need to look through Op to see if it's needed there
  "__global__ void COOT_FN(PREFIX,inplace_plus_array)(eT2* out, const eT1* A, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if (i < N)\n"
  "    {\n"
  "    out[i] += (eT2) A[i];\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_minus_array)(eT2* out, const eT1* A, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if (i < N)\n"
  "    {\n"
  "    out[i] -= (eT2) A[i];\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_mul_array)(eT2* out, const eT1* A, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if (i < N)\n"
  "    {\n"
  "    out[i] *= (eT2) A[i];\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,inplace_div_array)(eT2* out, const eT1* A, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if (i < N)\n"
  "    {\n"
  "    out[i] /= (eT2) A[i];\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_set_mat)(eT2* out, const eT1* A, const UWORD out_start_row, const UWORD out_start_col, const UWORD out_n_rows, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if( (row <= A_n_rows) && (col <= A_n_cols) ) \n"
  "    { \n"
  "    const UWORD out_index = (out_start_row + row) + ((out_start_col + col) * out_n_rows); \n"
  "    const UWORD   A_index = row + col*A_n_rows; \n"
  "    out[out_index] = (eT2) A[A_index];\n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_plus_mat)(eT2* out, const eT1* A, const UWORD out_start_row, const UWORD out_start_col, const UWORD out_n_rows, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if( (row <= A_n_rows) && (col <= A_n_cols) ) \n"
  "    { \n"
  "    const UWORD out_index = (out_start_row + row) + ((out_start_col + col) * out_n_rows); \n"
  "    const UWORD   A_index = row + col*A_n_rows; \n"
  "    out[out_index] += (eT2) A[A_index];\n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_minus_mat)(eT2* out, const eT1* A, const UWORD out_start_row, const UWORD out_start_col, const UWORD out_n_rows, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if( (row <= A_n_rows) && (col <= A_n_cols) ) \n"
  "    { \n"
  "    const UWORD out_index = (out_start_row + row) + ((out_start_col + col) * out_n_rows); \n"
  "    const UWORD   A_index = row + col*A_n_rows; \n"
  "    out[out_index] -= (eT2) A[A_index];\n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_schur_mat)(eT2* out, const eT1* A, const UWORD out_start_row, const UWORD out_start_col, const UWORD out_n_rows, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if( (row <= A_n_rows) && (col <= A_n_cols) ) \n"
  "    { \n"
  "    const UWORD out_index = (out_start_row + row) + ((out_start_col + col) * out_n_rows); \n"
  "    const UWORD   A_index = row + col*A_n_rows; \n"
  "    out[out_index] *= (eT2) A[A_index];\n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_inplace_div_mat)(eT2* out, const eT1* A, const UWORD out_start_row, const UWORD out_start_col, const UWORD out_n_rows, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if( (row <= A_n_rows) && (col <= A_n_cols) ) \n"
  "    { \n"
  "    const UWORD out_index = (out_start_row + row) + ((out_start_col + col) * out_n_rows); \n"
  "    const UWORD   A_index = row + col*A_n_rows; \n"
  "    out[out_index] /= (eT2) A[A_index];\n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_extract)(eT2* out, const eT1* in, const UWORD in_start_row, const UWORD in_start_col, const UWORD in_n_rows, const UWORD out_n_rows, const UWORD out_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  const UWORD col = blockIdx.y * blockDim.y + threadIdx.y; \n"
  "  if( (row <= out_n_rows) && (col <= out_n_cols) ) \n"
  "    { \n"
  "    const UWORD in_index = (in_start_row + row) + ((in_start_col + col) * in_n_rows); \n"
  "    const UWORD out_index = row + col * out_n_rows; \n"
  "    out[out_index] = (eT2) in[in_index];\n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_plus_scalar)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = ((eT2) (A[i] + val_pre)) + val_post;\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_neg_pre)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = -((eT2) A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_neg_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = ((eT2) -A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_minus_scalar_pre_pre)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void) val_pre;\n"
  "  \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = val_post - ((eT2) A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_minus_scalar_pre_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void) val_post;\n"
  "  \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) (val_pre - A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_minus_scalar_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = ((eT2) (A[i] - val_pre)) - val_post;\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_mul_scalar)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = ((eT2) (A[i] * val_pre)) * val_post;\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_div_scalar_pre)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    if (val_post == (eT2) (0)) \n" // if both are 0, we take it as val_pre == 0 and val_post unused
  "      { \n"
  "      out[i] = (eT2) (val_pre / A[i]); \n"
  "      } \n"
  "    else if (val_pre == (eT1) (0) && val_post != (eT2) (0)) \n"
  "      { \n"
  "      out[i] = val_post / ((eT2) A[i]); \n"
  "      } \n"
  "    else \n" // if both are nonzero, we apply sequentially----be careful!
  "      { \n"
  "      out[i] = val_post / ((eT2) (val_pre / A[i])); \n"
  "      } \n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_div_scalar_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = ((eT2) (A[i] / val_pre)) / val_post;\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_square_pre)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    const eT2 val = (eT2) A[i]; \n"
  "    out[i] = val * val;\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_square_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) (A[i] * A[i]); \n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_sqrt_pre)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) sqrt((fp_eT2) A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_sqrt_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) ((eT1) sqrt((fp_eT1) A[i]));\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_exp_pre)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) exp((fp_eT2) A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_exp_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) ((eT1) exp((fp_eT1) A[i]));\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_log_pre)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) log((fp_eT2) A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_log_post)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) ((eT1) log((fp_eT1) A[i]));\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_abs)(eT2* out, const eT1* A, const eT1 val_pre, const eT2 val_post, const UWORD N) \n"
  "  { \n"
  "  (void)(val_pre); \n"
  "  (void)(val_post); \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    out[i] = (eT2) ET1_ABS(A[i]);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,get_diag)(eT2* out, const eT1* A, const UWORD n_rows, const UWORD row_offset, const UWORD col_offset, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N) \n"
  "    { \n"
  "    const UWORD index = (i + row_offset) + (i + col_offset)*n_rows; \n"
  "    out[i] = (eT2) A[index]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,sum_colwise_conv_pre)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD col = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(col < A_n_cols) \n"
  "    { \n"
  "    const eT1* colptr = &(A[ col*A_n_rows ]); \n"
  "    eT2 acc = (eT2) (0); \n"
  "    for(UWORD i=0; i < A_n_rows; ++i) \n"
  "      { acc += (eT2) (colptr[i]); } \n"
  "    out[col] = acc; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,sum_rowwise_conv_pre)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(row < A_n_rows) \n"
  "    { \n"
  "    eT2 acc = (eT2)(0); \n"
  "    for(UWORD i=0; i < A_n_cols; ++i) \n"
  "      { acc += (eT2) (A[i*A_n_rows + row]); } \n"
  "    out[row] = acc; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,sum_colwise_conv_post)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD col = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(col < A_n_cols) \n"
  "    { \n"
  "    const eT1* colptr = &(A[ col*A_n_rows ]); \n"
  "    eT1 acc = (eT1) (0); \n"
  "    for(UWORD i=0; i < A_n_rows; ++i) \n"
  "      { acc += colptr[i]; } \n"
  "    out[col] = (eT2) (acc); \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,sum_rowwise_conv_post)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD A_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(row < A_n_rows) \n"
  "    { \n"
  "    eT1 acc = (eT1)(0); \n"
  "    for(UWORD i=0; i < A_n_cols; ++i) \n"
  "      { acc += A[i*A_n_rows + row]; } \n"
  "    out[row] = (eT2) (acc); \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_sum_colwise_conv_pre)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD start_row, const UWORD start_col, const UWORD sub_n_rows, const UWORD sub_n_cols) \n"
  "  { \n"
  "  const UWORD col = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(col < sub_n_cols) \n"
  "    { \n"
  "    const eT1* colptr = &(A[ (col + start_col)*A_n_rows + start_row ]); \n"
  "    eT2 acc = (eT2)(0); \n"
  "    for(UWORD i=0; i < sub_n_rows; ++i) \n"
  "      { acc += (eT2) colptr[i]; } \n"
  "    out[col] = acc; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_sum_rowwise_conv_pre)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD start_row, const UWORD start_col, const UWORD sub_n_rows, const UWORD sub_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(row < sub_n_rows) \n"
  "    { \n"
  "    eT2 acc = (eT2)(0); \n"
  "    for(UWORD i=0; i < sub_n_cols; ++i) \n"
  "      { acc += (eT2) A[(i+start_col)*A_n_rows + (row+start_row)]; } \n"
  "    out[row] = acc;\n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_sum_colwise_conv_post)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD start_row, const UWORD start_col, const UWORD sub_n_rows, const UWORD sub_n_cols) \n"
  "  { \n"
  "  const UWORD col = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(col < sub_n_cols) \n"
  "    { \n"
  "    const eT1* colptr = &(A[ (col + start_col)*A_n_rows + start_row ]); \n"
  "    eT1 acc = (eT1)(0); \n"
  "    for(UWORD i=0; i < sub_n_rows; ++i) \n"
  "      { acc += colptr[i]; } \n"
  "    out[col] = (eT2) acc; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,submat_sum_rowwise_conv_post)(eT2* out, const eT1* A, const UWORD A_n_rows, const UWORD start_row, const UWORD start_col, const UWORD sub_n_rows, const UWORD sub_n_cols) \n"
  "  { \n"
  "  const UWORD row = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(row < sub_n_rows) \n"
  "    { \n"
  "    eT1 acc = (eT1)(0); \n"
  "    for(UWORD i=0; i < sub_n_cols; ++i) \n"
  "      { acc += A[(i+start_col)*A_n_rows + (row+start_row)]; } \n"
  "    out[row] = (eT2) acc;\n"
  "    } \n"
  "  } \n"
  "\n"
  "__device__ void COOT_FN(PREFIX,dot_warp_reduce)(volatile twoway_promoted_eT* data, int tid) \n"
  "  { \n"
  "  data[tid] += data[tid + 32]; \n"
  "  data[tid] += data[tid + 16]; \n"
  "  data[tid] += data[tid + 8]; \n"
  "  data[tid] += data[tid + 4]; \n"
  "  data[tid] += data[tid + 2]; \n"
  "  data[tid] += data[tid + 1]; \n"
  "  } \n"
  "\n"
  // this kernel is technically incorrect if the size is not a factor of 2!
  "__global__ void COOT_FN(PREFIX,dot)(twoway_promoted_eT* out_mem, const eT1* A, const eT2* B, const UWORD n_elem) \n"
  "  { \n"
  "  twoway_promoted_eT* aux_mem = (twoway_promoted_eT*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  aux_mem[tid] = 0; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += (((twoway_promoted_eT) A[i]) * ((twoway_promoted_eT) B[i])) + \n"
  "        (((twoway_promoted_eT) A[i + blockDim.x]) * (((twoway_promoted_eT) B[i + blockDim.x]))); \n" // copy to local shared memory
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += (((twoway_promoted_eT) A[i]) * ((twoway_promoted_eT) B[i])); \n"
  "    } \n"
  "  __syncthreads(); \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 32; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] += aux_mem[tid + s]; \n"
  "      } \n"
  "    __syncthreads(); \n"
  "  } \n"
  "  \n"
  "  if (tid < 32) \n" // unroll last warp's worth of work
  "    { \n"
  "    COOT_FN(PREFIX,dot_warp_reduce)(aux_mem, tid); \n"
  "    } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,dot_small)(twoway_promoted_eT* out_mem, const eT1* A, const eT2* B, const UWORD n_elem) \n"
  "  { \n"
  "  twoway_promoted_eT* aux_mem = (twoway_promoted_eT*) aux_shared_mem; \n"
  "  \n"
  "  const UWORD tid = threadIdx.x; \n"
  "  UWORD i = blockIdx.x * (blockDim.x * 2) + threadIdx.x; \n"
  "  const UWORD grid_size = blockDim.x * 2 * gridDim.x; \n"
  "  \n"
  "  aux_mem[tid] = 0; \n"
  "  \n"
  "  while (i + blockDim.x < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += (((twoway_promoted_eT) A[i]) * ((twoway_promoted_eT) B[i])) + \n"
  "        (((twoway_promoted_eT) A[i + blockDim.x]) * (((twoway_promoted_eT) B[i + blockDim.x]))); \n" // copy to local shared memory
  "    i += grid_size; \n"
  "    } \n"
  "  if (i < n_elem) \n"
  "    { \n"
  "    aux_mem[tid] += (((twoway_promoted_eT) A[i]) * ((twoway_promoted_eT) B[i])); \n"
  "    } \n"
  "  \n"
  "  for (UWORD s = blockDim.x / 2; s > 0; s >>= 1) \n"
  "    { \n"
  "    if (tid < s) \n"
  "      { \n"
  "      aux_mem[tid] += aux_mem[tid + s]; \n"
  "      } \n"
  "  } \n"
  "  \n"
  "  if (tid == 0) \n"
  "    { \n"
  "    out_mem[blockIdx.x] = aux_mem[0]; \n"
  "    } \n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,convert_type)(eT2* out, const eT1* in, const UWORD len) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if (i < len) \n"
  "    { \n"
  "    const eT1 in_val = in[i]; \n"
  "    out[i] = (eT2) (in_val); \n"
  "    } \n"
  "  } \n"
  "\n";

  return source;
}



inline
std::string
get_cuda_threeway_kernel_src()
  {

  std::string source = \

  "__global__ void COOT_FN(PREFIX,equ_array_plus_array)(eT3* out, const eT1* A, const eT2* B, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    const threeway_promoted_eT a_val = (threeway_promoted_eT) A[i];\n"
  "    const threeway_promoted_eT b_val = (threeway_promoted_eT) B[i];\n"
  "    out[i] = (eT3) (a_val + b_val);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_minus_array)(eT3* out, const eT1* A, const eT2* B, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    const threeway_promoted_eT a_val = (threeway_promoted_eT) A[i];\n"
  "    const threeway_promoted_eT b_val = (threeway_promoted_eT) B[i];\n"
  "    out[i] = (eT3) (a_val - b_val);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_mul_array)(eT3* out, const eT1* A, const eT2* B, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    const threeway_promoted_eT a_val = (threeway_promoted_eT) A[i];\n"
  "    const threeway_promoted_eT b_val = (threeway_promoted_eT) B[i];\n"
  "    out[i] = (eT3) (a_val * b_val);\n"
  "    }\n"
  "  } \n"
  "\n"
  "__global__ void COOT_FN(PREFIX,equ_array_div_array)(eT3* out, const eT1* A, const eT2* B, const UWORD N) \n"
  "  { \n"
  "  const UWORD i = blockIdx.x * blockDim.x + threadIdx.x; \n"
  "  if(i < N)\n"
  "    {\n"
  "    const threeway_promoted_eT a_val = (threeway_promoted_eT) A[i];\n"
  "    const threeway_promoted_eT b_val = (threeway_promoted_eT) B[i];\n"
  "    out[i] = (eT3) (a_val / b_val);\n"
  "    }\n"
  "  } \n"
  "\n";

  return source;
  }
